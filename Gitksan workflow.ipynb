{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7b81843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import re\n",
    "import sys\n",
    "\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc05fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')\n",
    "\n",
    "import spacy_processing as sp # Uses 'en_core_web_sm' and 'es_core_news_sm'\n",
    "import analysis as gla\n",
    "import utils as utils\n",
    "import to_wapiti as tw\n",
    "import IGT_helper as igth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40488959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e669054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d771448e",
   "metadata": {},
   "source": [
    "## Split IGT file\n",
    "Please remove any empty lines at the end of the IGT file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49047b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 sentences.\n"
     ]
    }
   ],
   "source": [
    "train_gitksan_uncover = open('../IGT_ST/gitksan/git-train-track2-uncovered', 'r').read()\n",
    "igth.split_uncovered(train_gitksan_uncover, './data/raw_corpus/', 'raw_gitksan_train', lower=False)\n",
    "#There are 31 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ac17bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42 sentences.\n"
     ]
    }
   ],
   "source": [
    "dev_gitksan_uncover = open('../IGT_ST/gitksan/git-dev-track2-uncovered', 'r').read()\n",
    "igth.split_uncovered(dev_gitksan_uncover, './data/raw_corpus/', 'raw_gitksan_dev', lower=False)\n",
    "#There are 42 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9525dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 sentences.\n"
     ]
    }
   ],
   "source": [
    "test_gitksan_cover = open('../IGT_ST/gitksan/git-test-track2-covered', 'r').read()\n",
    "igth.split_uncovered(test_gitksan_cover, './data/raw_corpus/', 'raw_gitksan_test', covered=True, lower=False)\n",
    "#There are 37 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89e9a92",
   "metadata": {},
   "source": [
    "## Convert to Wapiti format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a86cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def create_corpus(path, file_start, test=False):\n",
    "    '''Create the language Corpus object from a path.'''\n",
    "    src_data = open(os.path.join(path, f'{file_start}_src.txt'), 'r').read()\n",
    "    if test:\n",
    "        glo_data = ''\n",
    "    else:\n",
    "        glo_data = open(os.path.join(path, f'{file_start}_glo.txt'), 'r').read()\n",
    "    trg_data = open(os.path.join(path, f'{file_start}_trg.txt'), 'r').read()\n",
    "    return tw.Corpus(src_data, glo_data, trg_data, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb766896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus has 31 sentences.\n"
     ]
    }
   ],
   "source": [
    "train_gitksan_corpus = create_corpus('./data/raw_corpus/', 'raw_gitksan_train')\n",
    "#The corpus has 31 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "565cbf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long around completely across live white person\n"
     ]
    }
   ],
   "source": [
    "# Generate the file with lexical glosses only\n",
    "lof_gitksan_train = igth.lex_only_file(train_gitksan_corpus) \n",
    "print(lof_gitksan_train[0])\n",
    "#'long around completely across live white person'\n",
    "#utils.save_file('\\n'.join(lof_gitksan_train), './data/raw_corpus/train_gitksan_lex_only.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c634ee",
   "metadata": {},
   "source": [
    "### !!! Use SimAlign here to align the training lexical gloss file with the translation !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4010690c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using copy and position features\n",
      "Using morphological features in input and gold labels\n",
      "There are five inputs and three outputs.\n",
      "There are seven inputs and five outputs (CHANGE).\n",
      "12 units (label position: 7)\n",
      " creating a dictionary with 21 sentences\n",
      "Lowered token: Stockholm\n",
      "Lowered token: IBM\n",
      "Lowered token: Spain\n",
      "Lowered token: Denmark\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n",
      "Lowered token: Canadanska\n",
      "Using a train dataset of 21 sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: IBM\n",
      "Lowered token: IBM\n",
      "Lowered token: Spain\n",
      "Lowered token: Spain\n",
      "Lowered token: Denmark\n",
      "Lowered token: Denmark\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 31/31 [00:00<00:00, 155.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n",
      "Lowered token: Canadanska\n",
      "Lowered token: Canadanska\n",
      "Use a hybrid dictionary with projected PoS tags\n",
      "Using a train dataset of 21 sentences.\n",
      "'nakw 0 5 'na akw 0 1/4 long lex ADJ 0 1/4\n",
      "hl 1 2 hl hl 0 1/4 CN gram GRAM_GLOSS -1 -2\n",
      "hli 0 3 hli h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate shared task file - training data\n",
    "train_index_dict = 31 #- 10 # Change here\n",
    "method = 'dist' # Change here\n",
    "gitksan_alignment_m = open('./data/raw_corpus/git_train_aligned_0.txt', 'r').read() # SimAlign file\n",
    "ctwf_gitksan_train_mdistex = train_gitksan_corpus.to_wapiti_format(gitksan_alignment_m, expand=True, verbose=False,\n",
    "                                                           train_index=train_index_dict, pos=True, \n",
    "                                                           label_format=method) #, punctuation=True)\n",
    "\n",
    "print(ctwf_gitksan_train_mdistex[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8ef317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.save_file(ctwf_gitksan_train_mdistex, \n",
    "#                f'./data/wapiti_format/wapiti_for_lost_gitksan_train_match_{train_index_dict}_{method}.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b9e57d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'nakw\": ('long', 2, 'ADJ'), 'hl': ('CN', 33, 'GRAM_GLOSS'), 'hli': ('PART', 1, 'GRAM_GLOSS'), 'daa': ('SPT', 2, 'GRAM_GLOSS'), \"'wihl\": ('around', 2, 'NOUN'), 'wil': ('LVB', 4, 'GRAM_GLOSS'), \"'y\": ('1SG.II', 17, 'GRAM_GLOSS'), 'g̲oo': ('LOC', 10, 'GRAM_GLOSS'), 'wag̲ayt': ('completely', 1, 'PRON'), 'an': ('NMLZ', 4, 'GRAM_GLOSS'), 'doosda': ('across', 1, 'ADV'), 'jok̲': ('live', 1, 'VERB'), 'amxsiwaa': ('white.person', 1, '?'), 'ii': ('CCNJ', 29, 'GRAM_GLOSS'), 'n': ('1.I', 7, 'GRAM_GLOSS'), \"'wa\": ('find', 1, 'VERB'), \"hahla'lst\": ('work', 2, 'NOUN'), 'Stockholm': ('Stockholm', 3, 'PROPN'), 'si': ('CAUS1', 1, 'GRAM_GLOSS'), 'wa': ('name', 1, 'PRON'), 't': ('3.II', 5, 'GRAM_GLOSS'), 'diit': ('3PL.II', 1, 'GRAM_GLOSS'), 'IBM': ('IBM', 1, 'GRAM_GLOSS'), 'hlaa': ('INCEP', 4, 'GRAM_GLOSS'), \"k'i'y\": ('one', 1, 'NUM'), \"k'uuhl\": ('year', 1, 'NOUN'), 'sdil': ('accompany', 1, 'VERB'), \"siip'\": ('like', 1, 'CCONJ'), 'in': ('CAUS2', 1, 'GRAM_GLOSS'), 'sxw': ('ANTIP', 2, 'GRAM_GLOSS'), 'g̲an': ('REAS', 2, 'GRAM_GLOSS'), 'naks': ('spouse', 1, 'NOUN'), 'Spain': ('Spain', 1, 'PROPN'), 'i': ('TR', 1, 'GRAM_GLOSS'), \"'m\": ('1PL.II', 5, 'GRAM_GLOSS'), 'guxws': ('back', 1, 'ADV'), 'luu': ('in', 1, 'ADP'), 'yalt': ('return', 1, 'NOUN'), 'xw': ('PASS', 3, 'GRAM_GLOSS'), 'baasax̲': ('separate', 1, 'VERB'), 'Denmark': ('Denmark', 1, 'PROPN'), 'yuxw': ('follow', 1, 'CCONJ'), 'train': ('train', 1, 'NOUN'), 'yee': ('go', 3, 'VERB'), 'bakw': ('arrive.PL', 1, 'VERB'), \"ha'w\": ('go.home', 2, '?'), \"gwila'l\": ('three', 1, 'NUM'), 'g̲anuutxw': ('week', 1, 'NOUN'), 'nee': ('NEG', 4, 'GRAM_GLOSS'), 'dii': ('FOC', 4, 'GRAM_GLOSS'), \"lax̲'ni\": ('hear', 1, 'AUX'), 'gi': ('place', 1, 'NOUN'), 'geenix': ('upriver', 1, 'ADV'), 'ap': ('VER', 2, 'GRAM_GLOSS'), 'yukw': ('IPFV', 2, 'GRAM_GLOSS'), 'ha': ('INS', 3, 'GRAM_GLOSS'), \"'nii\": ('on', 2, 'CCONJ'), \"sgwaa'ytxw\": ('rest', 1, 'PRON'), 'naa': ('who', 3, 'CCONJ'), 'dim': ('PROSP', 3, 'GRAM_GLOSS'), \"'witxw\": ('come', 1, 'AUX'), 'it': ('SX', 2, 'GRAM_GLOSS'), 'loo': ('OBL', 3, 'GRAM_GLOSS'), 'dok̲': ('take.PL', 1, 'PRON'), \"mail'y\": ('mail', 1, 'NOUN'), 'hla': ('PART', 1, 'GRAM_GLOSS'), 'g̲ook̲': ('first', 1, 'CCONJ'), \"ky'aa\": ('short.prepare', 1, '?'), 'isxw': ('pee', 1, 'NOUN'), 'wilp': ('house', 1, 'VERB'), 'xseek̲': ('go.out.PL', 1, '?'), 'imaa': ('EPIS', 1, 'GRAM_GLOSS'), 'ni': ('1.I', 1, 'GRAM_GLOSS'), 'sg̲a': ('block.way', 1, '?'), \"t'akw\": ('turn', 1, 'AUX'), \"aats'ip\": ('door', 1, 'DET'), 'xsaxw': ('go.out', 1, '?'), \"'nim\": ('DES', 1, 'GRAM_GLOSS'), \"k̲'ak̲\": ('open', 1, 'PART'), 'xsi': ('out', 1, 'VERB'), 'hlguxws': ('unable.to', 1, '?'), 'lip': ('SELF', 1, 'GRAM_GLOSS'), 'ligi': ('DWID', 4, 'GRAM_GLOSS'), 'agwi': ('what', 1, 'CCONJ'), 'bak̲': ('try', 1, 'PRON'), 'a': ('TR', 1, 'GRAM_GLOSS'), \"k̲'aa\": ('short.time', 1, '?'), 'giihl': ('lay', 1, 'VERB'), 'lax̲': ('on', 1, 'DET'), 'wan': ('sit.PL', 1, 'NOUN'), 'ak̲': ('lack', 1, 'AUX'), 'he': ('say', 1, 'PART'), 'yats': ('hit', 2, 'VERB'), 'pipe': ('pipe', 2, 'NOUN'), \"gya'a\": ('see', 1, 'VERB'), 'sgi': ('lie.on', 1, '?'), \"yo'oxs\": ('wash', 1, 'NOUN'), 'xhlii': ('all.the.way', 1, '?'), 'guu': ('take', 1, 'VERB'), 'pole': ('pole', 1, 'NOUN'), 'up': ('in.case', 1, '?'), 'ji': ('IRR', 2, 'GRAM_GLOSS')}\n"
     ]
    }
   ],
   "source": [
    "# Save the training dictionary in pickle\n",
    "print(train_gitksan_corpus.train_dict)\n",
    "# It corresponds to f'./data/wapiti_format/dictionary_gitksan_train_match_{train_index_dict}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddf88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f550a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus has 42 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Dev data\n",
    "dev_gitksan_corpus = create_corpus('./data/raw_corpus/', 'raw_gitksan_dev') #, test=True)\n",
    "\n",
    "dev_git_trg = open('./data/raw_corpus/raw_gitksan_dev_trg.txt', 'r').read()\n",
    "#The corpus has 42 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e971b7e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0 1-1 2-2 3-3 4-4 5-5 6-6 7-7 8-8 9-9 10-10\n",
      "0-0 1-1 2-2 3-3 4-4 5-5\n",
      "0-0 1-1 2-2 3-3 4-4 5-5 6-6 7-\n",
      "Using copy and position features\n",
      "Using morphological features in input and gold labels\n",
      "There are five inputs and three outputs.\n",
      "There are seven inputs and five outputs (CHANGE).\n",
      "12 units (label position: 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████                             | 13/42 [00:00<00:00, 128.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Jacob\n",
      "Lowered token: Brown\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Jacob\n",
      "Lowered token: Brown\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 42/42 [00:00<00:00, 139.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Man\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "k̲'ay F 5 k̲' 'ay 0 1/4 still lex SCONJ 0 1/4\n",
      "yukw 0 4 yuk ukw 0 1/4 IPFV gram GRAM_GLOSS -1 -2\n",
      "hl 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#method = 'dist' # Change here\n",
    "\n",
    "lof_dev = igth.lex_only_file(dev_gitksan_corpus)\n",
    "git_alignment_m = igth.create_dummy_alignment('\\n'.join(lof_dev), dev_git_trg) # Dummy\n",
    "print(git_alignment_m[0:100])\n",
    "\n",
    "ctwf_git_dev_mdistex = dev_gitksan_corpus.to_wapiti_format(git_alignment_m, expand=True, \n",
    "                                                   train_index=0, pos=True, \n",
    "                                                   label_format=method) #, punctuation=True)\n",
    "print(ctwf_git_dev_mdistex[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6583261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.save_file(ctwf_git_dev_mdistex, f'./data/wapiti_format/wapiti_for_lost_gitksan_dev_match_{method}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7001bf1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus has 37 sentences.\n",
      "Using copy and position features\n",
      "Using morphological features in input and gold labels\n",
      "There are five inputs and three outputs.\n",
      "There are seven inputs and five outputs (CHANGE).\n",
      "12 units (label position: 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 37/37 [00:00<00:00, 214.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Skeena\n",
      "Lowered token: Meji'aadin\n",
      "Lowered token: Agent\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: English\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Oakalla\n",
      "Lowered token: Prison\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "dim F 3 dim dim 0 1/4\n",
      "mehl 0 4 meh ehl 0 1/4\n",
      "d 1 1 d d 0 1/4\n",
      "i 2 1 i i 1 1/4\n",
      "'y 3 2 'y 'y 0 1/4\n",
      "wila\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "test_gitksan_corpus = create_corpus('./data/raw_corpus/', 'raw_gitksan_test', test=True)\n",
    "#The corpus has 37 sentences.\n",
    "\n",
    "#method = 'dist' # Change here\n",
    "\n",
    "git_alignment_m = '' #create_dummy_alignment('\\n'.join(lof_dev), dev_git_trg) # Test data, so no alignment\n",
    "ctwf_git_test_mdistex = test_gitksan_corpus.to_wapiti_format(git_alignment_m, expand=True, \n",
    "                                                   train_index=0, pos=True, \n",
    "                                                   label_format=method) #, punctuation=True)\n",
    "#corpus_to_wapiti_format(pp_tsez, pp_tsez_gloss, pp_tsez_translation, tsez_alignment_a, expand=True, train_index=200) #, pos=True)\n",
    "print(ctwf_git_test_mdistex[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90a5d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.save_file(ctwf_git_test_mdistex, f'./data/wapiti_format/wapiti_for_lost_gitksan_test_match_{method}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859997b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a27fbc2a",
   "metadata": {},
   "source": [
    "### Concatenate all the Wapiti format files (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69bdbfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gitksan\n",
    "igth.concatenate_files('./data/wapiti_format/', './data/raw_corpus', 'gitksan', 'dist', #21)\n",
    "                  train_size=31, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46e928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e8545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3680b5b",
   "metadata": {},
   "source": [
    "### Convert to Lost format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f48d40e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!DIST, TO DELETE .\n",
      "The search space will take into account a training dictionary.\n",
      "Check the inference labels: code??\n",
      "Using copy and position features\n",
      "Using morphological features in input and gold labels\n",
      "There are five inputs and three outputs.\n",
      "There are seven inputs and five outputs (CHANGE).\n",
      "12 units (label position: 7)\n",
      "31 training and 37 test sentences\n",
      "42 developement sentences\n",
      "31 training and 37 test sentences\n",
      "42 developement sentences\n",
      "Lowered token: Stockholm\n",
      "Lowered token: IBM\n",
      "Lowered token: Spain\n",
      "Lowered token: Denmark\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n",
      "Lowered token: Canadanska\n",
      "Processing 31 train sentences.\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Skeena\n",
      "Lowered token: Meji'aadin\n",
      "Lowered token: Agent\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: English\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Oakalla\n",
      "Lowered token: Prison\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Processing 37 test sentences.\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Jacob\n",
      "Lowered token: Brown\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Processing 42 dev sentences.\n",
      "Development dataset of size: 42\n",
      "\tThere are 139 labels\n",
      "\tComplex output with three labels.\n",
      "All pos labels {'PART', 'SCONJ', 'INTJ', '?', 'PROPN', 'AUX', 'GRAM_GLOSS', 'NUM', 'PRON', 'NOUN', 'ADJ', 'VERB', 'DET', 'ADP', 'CCONJ', 'ADV'}\n",
      "Creating a search space for a train dataset (output labels included)\n",
      "\tLabel position: 7\n",
      "\tThere are 139 labels\n",
      "There are 48 possible grammatical labels\n",
      "\tThere are 139 labels\n",
      "There are 16 possible PoS tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: IBM\n",
      "Lowered token: IBM\n",
      "Lowered token: Spain\n",
      "Lowered token: Spain\n",
      "Lowered token: Denmark\n",
      "Lowered token: Denmark\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n",
      "Lowered token: Stockholm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████▋               | 20/31 [00:00<00:00, 97.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Stockholm\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Gigeenix\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n",
      "Lowered token: Sunday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 31/31 [00:00<00:00, 91.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Canadanska\n",
      "Lowered token: Canadanska\n",
      "Creating a search space for a test dataset (no output label)\n",
      "A label set for grammatical glosses is defined with 48 labels.\n",
      "A label set for PoS tags is defined with 16 PoS tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "gik'uuhl arrive.PL|lex|VERB|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "gitwinhlguu'l heart|lex|ADV|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Gitwinhlguu'l live|lex|VERB|0|-1\n",
      "diit on|lex|DET|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "xwin live|lex|VERB|0|-1\n",
      "surveyors arrive.PL|lex|VERB|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▌                                  | 8/37 [00:00<00:00, 71.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ist long|lex|ADJ|0|-1\n",
      "Lowered token: Skeena\n",
      "Lowered token: Meji'aadin\n",
      "Lowered token: Skeena\n",
      "Lowered token: Meji'aadin\n",
      "reserve find|lex|VERB|0|-1\n",
      "Lowered token: Agent\n",
      "Lowered token: Agent\n",
      "Lowered token: Agent\n",
      "Lowered token: Agent\n",
      "diit heart|lex|ADV|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "si'm small|lex|DET|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "dihiida say|lex|VERB|0|-1\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "surveyors say|lex|VERB|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "surveyors arrive.PL|lex|VERB|0|-1\n",
      "jok̲ live|lex|VERB|0|-1\n",
      "si'm say|lex|VERB|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████▌                        | 16/37 [00:00<00:00, 71.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surveyors continually|lex|VERB|0|-1\n",
      "'nidiit lie.on|lex|?|0|-1\n",
      "'m \n",
      "diit \n",
      "surveyors \n",
      "Lowered token: English\n",
      "Lowered token: English\n",
      "t take.PL|lex|PRON|0|-1\n",
      "surveyors take.PL|lex|PRON|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▏            | 26/37 [00:00<00:00, 80.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luuhligyootxw \n",
      "surveyors \n",
      "police arrive.PL|lex|VERB|0|-1\n",
      "surveyors who|lex|CCONJ|0|-1\n",
      "diit in|lex|ADP|0|-1\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Kitwancool\n",
      "Gitwinhlguu'l say|lex|VERB|0|-1\n",
      "'m lie.on|lex|?|0|-1\n",
      "Lowered token: Oakalla\n",
      "Lowered token: Prison\n",
      "Lowered token: Oakalla\n",
      "Lowered token: Prison\n",
      "it place|lex|NOUN|0|-1\n",
      "diit in|lex|ADP|0|-1\n",
      "surveyors arrive.PL|lex|VERB|0|-1\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Lowered token: Indian\n",
      "Lowered token: Agent\n",
      "Lowered token: Kitwancool\n",
      "Gitwinhlguu'l on|lex|ADP|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 37/37 [00:00<00:00, 79.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nuu'm \n",
      "reserve lie.on|lex|?|0|-1\n",
      "t say|lex|VERB|0|-1\n",
      "it \n",
      "Creating a search space for a dev dataset (no output label)\n",
      "A label set for grammatical glosses is defined with 48 labels.\n",
      "A label set for PoS tags is defined with 16 PoS tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Lowered token: Gitsegyukla\n",
      "Gijigyukwhla'a small|lex|DET|0|-1\n",
      "'m house|lex|VERB|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████▍                                  | 9/42 [00:00<00:00, 83.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Jacob\n",
      "Lowered token: Brown\n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Lowered token: Jacob\n",
      "Lowered token: Brown\n",
      "Brown name|lex|PRON|0|-1\n",
      "t \n",
      "t go|lex|VERB|0|-1\n",
      "t take.PL|lex|PRON|0|-1\n",
      "t \n",
      "'y \n",
      "n say|lex|VERB|0|-1\n",
      "'nit block.way|lex|?|0|-1\n",
      "x̲adaa see|lex|VERB|0|-1\n",
      "'y \n",
      "diya \n",
      "'y \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████▍                        | 18/42 [00:00<00:00, 87.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "Man on|lex|ADP|0|-1\n",
      "'y see|lex|VERB|0|-1\n",
      "t \n",
      "x̲adaa \n",
      "t on|lex|ADP|0|-1\n",
      "bisde'y say|lex|VERB|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▋              | 28/42 [00:00<00:00, 91.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it \n",
      "bisde'y go|lex|VERB|0|-1\n",
      "x̲adaa go|lex|VERB|0|-1\n",
      "gyet \n",
      "t go.home|lex|?|0|-1\n",
      "t see|lex|VERB|0|-1\n",
      "t say|lex|VERB|0|-1\n",
      "gi place|lex|NOUN|0|-1\n",
      "n house|lex|VERB|0|-1\n",
      "bisde'y go.home|lex|?|0|-1\n",
      "t say|lex|VERB|0|-1\n",
      "x̲adaa \n",
      "bisde'y block.way|lex|?|0|-1\n",
      "bisde'y \n",
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "bisde'y say|lex|VERB|0|-1\n",
      "g̲an on|lex|ADP|0|-1\n",
      "betl' on|lex|ADP|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:00<00:00, 87.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisde'y block.way|lex|?|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████| 42/42 [00:00<00:00, 86.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered token: Man\n",
      "Lowered token: Man\n",
      "aa see|lex|VERB|0|-1\n",
      "Lowered token: Man\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Man\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Betl' on|lex|ADP|0|-1\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Lowered token: Betl'a\n",
      "Lowered token: Betl\n",
      "Betl' on|lex|ADP|0|-1\n",
      "'y say|lex|VERB|0|-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Dist labels, match PoS - dictionary\n",
    "%run ../gloss_lost/wapiti_to_lost.py './data/wapiti_format/wapiti_for_lost_gitksan_conc_match_31_dist.txt' './data/raw_corpus/raw_gitksan_conc_trg.txt' \\\n",
    "--train_size 31 --test_size 37 --save_path './data/lost_format/' -o 'gitksan_conc_match_dist_31' \\\n",
    "--train_dict './data/wapiti_format/dictionary_gitksan_train_match_31.pkl' --dev_size 42 --pos --label_type dist \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c2f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a28586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b084ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371173ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
